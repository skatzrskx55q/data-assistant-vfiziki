import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search, get_model
import datetime
import pandas as pd
import os
import csv
import torch  # <-- –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏ —Ç–µ–Ω–∑–æ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

st.set_page_config(page_title="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑ –§–õ", layout="centered")
st.title("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑")

LOG_FILE = "query_log.csv"

# üîß –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
def log_query(query, semantic_count, keyword_count, status):
    is_new = not os.path.exists(LOG_FILE)
    with open(LOG_FILE, "a", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        if is_new:
            writer.writerow(["time", "query", "semantic_results", "keyword_results", "status"])
        writer.writerow([
            datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            query.strip(),
            semantic_count,
            keyword_count,
            status
        ])

@st.cache_data
def get_data():
    df = load_all_excels()
    model = get_model()
    # —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –ø–æ–ª–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ attrs
    df.attrs['phrase_embs'] = model.encode(df['phrase_proc'].tolist(), convert_to_tensor=True)
    return df

df = get_data()

# üîò –í—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º–∞—Ç–∏–∫–∏
all_topics = sorted({topic for topics in df['topics'] for topic in topics})
selected_topics = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–∏—Å–∫–∞):", all_topics)
filter_search_by_topics = st.checkbox("–ò—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–µ–º–∞—Ç–∏–∫–∞—Ö", value=False)

# üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º
if selected_topics:
    st.markdown("### üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º:")
    filtered_df = df[df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))]
    for row in filtered_df.itertuples():
        with st.container():
            st.markdown(
                f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                    <div style="font-size: 18px; font-weight: 600; color: #333;">üìù {row.phrase_full}</div>
                    <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(row.topics)}</strong></div>
                </div>""",
                unsafe_allow_html=True
            )
            if row.comment and str(row.comment).strip().lower() != "nan":
                with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                    st.markdown(row.comment)

# üì• –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:")

if query:
    try:
        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ñ–∏–ª—å—Ç—Ä, —Å—É–∂–∞–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è –ø–æ–∏—Å–∫–∞
        search_df = df
        if filter_search_by_topics and selected_topics:
            mask = df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))
            search_df = df[mask]

            # –ü–æ–¥—Ä–µ–∑–∞–µ–º/–Ω–∞–∑–Ω–∞—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è search_df, —á—Ç–æ–±—ã –æ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ —Å—Ç—Ä–æ–∫–∞–º
            # –ë–µ—Ä—ë–º –ø–æ–ª–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ df.attrs['phrase_embs'] –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –µ–≥–æ –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º search_df
            full_embs = df.attrs.get('phrase_embs', None)
            if full_embs is not None:
                try:
                    indices = search_df.index.tolist()
                    if isinstance(full_embs, torch.Tensor):
                        if indices:
                            # –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–µ–Ω–∑–æ—Ä –ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∏–Ω–¥–µ–∫—Å–∞–º (–æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –ø–æ—Ä—è–¥–∫–æ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è)
                            search_df.attrs['phrase_embs'] = full_embs[indices]
                        else:
                            # –ø—É—Å—Ç–æ–π –Ω–∞–±–æ—Ä ‚Äî —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π —Ç–µ–Ω–∑–æ—Ä –Ω—É–∂–Ω–æ–π —à–∏—Ä–∏–Ω—ã
                            search_df.attrs['phrase_embs'] = full_embs.new_empty((0, full_embs.size(1)))
                    else:
                        # –µ—Å–ª–∏ —ç—Ç–æ numpy array –∏–ª–∏ –ø–æ—Ö–æ–∂–µ–µ
                        import numpy as np
                        arr = np.asarray(full_embs)
                        search_df.attrs['phrase_embs'] = arr[indices]
                except Exception:
                    # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ ‚Äî –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è search_df (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
                    model = get_model()
                    if not search_df.empty:
                        search_df.attrs['phrase_embs'] = model.encode(search_df['phrase_proc'].tolist(), convert_to_tensor=True)
                    else:
                        search_df.attrs['phrase_embs'] = None

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if search_df.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º.")
        else:
            results = semantic_search(query, search_df)
            exact_results = keyword_search(query, search_df)

            # –ó–∞–ø–∏—Å—å –≤ –ª–æ–≥
            log_query(
                query,
                semantic_count=len(results),
                keyword_count=len(exact_results),
                status="–Ω–∞–π–¥–µ–Ω–æ" if results or exact_results else "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            )

            if results:
                st.markdown("### üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
                for score, phrase_full, topics, comment in results:
                    with st.container():
                        st.markdown(
                            f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                                <div style="font-size: 18px; font-weight: 600; color: #333;">üß† {phrase_full}</div>
                                <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics)}</strong></div>
                                <div style="margin-top: 2px; font-size: 13px; color: #999;">üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.2f}</div>
                            </div>""",
                            unsafe_allow_html=True
                        )
                        if comment and str(comment).strip().lower() != "nan":
                            with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                                st.markdown(comment)
            else:
                st.warning("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —É–º–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

            if exact_results:
                st.markdown("### üß∑ –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫:")
                for phrase, topics, comment in exact_results:
                    with st.container():
                        st.markdown(
                            f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                                <div style="font-size: 18px; font-weight: 600; color: #333;">üìå {phrase}</div>
                                <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics)}</strong></div>
                            </div>""",
                            unsafe_allow_html=True
                        )
                        if comment and str(comment).strip().lower() != "nan":
                            with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                                st.markdown(comment)
            else:
                st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–æ—á–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")

# –ë–ª–æ–∫ –ª–æ–≥–æ–≤
with st.expander("‚öôÔ∏è –õ–æ–≥–∏ (–¥–ª—è –∞–¥–º–∏–Ω–æ–≤)", expanded=False):
    if st.button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –ª–æ–≥–∏"):
        if os.path.exists(LOG_FILE):
            with open(LOG_FILE, "rb") as f:
                st.download_button("–°–∫–∞—á–∞—Ç—å –∫–∞–∫ CSV", f.read(), file_name="logs.csv", mime="text/csv")
        else:
            st.info("–§–∞–π–ª –ª–æ–≥–æ–≤ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

    if st.button("üóë –û—á–∏—Å—Ç–∏—Ç—å –ª–æ–≥–∏"):
        if os.path.exists(LOG_FILE):
            open(LOG_FILE, "w").close()
        st.success("–õ–æ–≥–∏ –æ—á–∏—â–µ–Ω—ã!")
