import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search, get_model
import torch  # –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏

st.title("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑")

@st.cache_data
def get_data():
    df = load_all_excels()
    model = get_model()
    df.attrs['phrase_embs'] = model.encode(df['phrase_proc'].tolist(), convert_to_tensor=True)
    return df

df = get_data()

# üîò –í—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º–∞—Ç–∏–∫–∏
all_topics = sorted({topic for topics in df['topics'] for topic in topics})

# --- –í–∫–ª–∞–¥–∫–∏ ---
tab1, tab2, tab3 = st.tabs(["üîç –ü–æ–∏—Å–∫", "üö´ –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º", "‚úÖ/‚ùå –î–∞ –∏ –ù–µ—Ç"])

# ============= TAB 1: –ü–û–ò–°–ö =============
with tab1:
    selected_topics = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–∏—Å–∫–∞):", all_topics)
    filter_search_by_topics = st.checkbox("–ò—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–µ–º–∞—Ç–∏–∫–∞—Ö", value=False)

    # üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º
    if selected_topics:
        st.markdown("### üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º:")
        filtered_df = df[df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))]
        for row in filtered_df.itertuples():
            with st.container():
                st.markdown(
                    f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                        <div style="font-size: 18px; font-weight: 600; color: #333;">üìù {row.phrase_full}</div>
                        <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(row.topics)}</strong></div>
                    </div>""",
                    unsafe_allow_html=True
                )
                if row.comment and str(row.comment).strip().lower() != "nan":
                    with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                        st.markdown(row.comment)

    # üì• –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:")

    if query:
        try:
            search_df = df
            if filter_search_by_topics and selected_topics:
                mask = df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))
                search_df = df[mask].copy()

                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ DF (–Ω–∞–¥–µ–∂–Ω–µ–µ)
                if not search_df.empty:
                    model = get_model()
                    search_df.attrs['phrase_embs'] = model.encode(search_df['phrase_proc'].tolist(), convert_to_tensor=True)
                else:
                    search_df.attrs['phrase_embs'] = torch.empty((0, 384))  # –ü—É—Å—Ç–æ–π —Ç–µ–Ω–∑–æ—Ä (–ø—Ä–∏–º–µ—Ä dim=384 –¥–ª—è –º–æ–¥–µ–ª–∏)

            if search_df.empty:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º.")
            else:
                results = semantic_search(query, search_df)
                if results:
                    st.markdown("### üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
                    for score, phrase_full, topics, comment in results:
                        with st.container():
                            st.markdown(
                                f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                                    <div style="font-size: 18px; font-weight: 600; color: #333;">üß† {phrase_full}</div>
                                    <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics)}</strong></div>
                                    <div style="margin-top: 2px; font-size: 13px; color: #999;">üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.2f}</div>
                                </div>""",
                                unsafe_allow_html=True
                            )
                            if comment and str(comment).strip().lower() != "nan":
                                with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                                    st.markdown(comment)
                else:
                    st.warning("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —É–º–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

                exact_results = keyword_search(query, search_df)
                if exact_results:
                    st.markdown("### üß∑ –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫:")
                    for phrase, topics, comment in exact_results:
                        with st.container():
                            st.markdown(
                                f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                                    <div style="font-size: 18px; font-weight: 600; color: #333;">üìå {phrase}</div>
                                    <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics)}</strong></div>
                                </div>""",
                                unsafe_allow_html=True
                            )
                            if comment and str(comment).strip().lower() != "nan":
                                with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                                    st.markdown(comment)
                else:
                    st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–æ—á–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")


# ============= TAB 2: –ù–ï –ò–°–ü–û–õ–¨–ó–£–ï–ú =============
with tab2:
    st.markdown("### üö´ –õ–æ–∫–∞–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ **–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º**")
    unused_topics = [
        "Local_Balance_Transfer",
        "Local_Friends",
        "Local_Next_Payment",
        "Local_Order_Cash",
        "Local_Other_Cashback",  # –î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–ø—è—Ç–∞—è
        "Local_RemittanceStatus",
        "–ü–æ–¥–æ–∂–¥–∏ (Wait)",
        "Local_X5",
        "PassportChangeFirst",
        "PassportChangeSecond",
        "–ú–µ–Ω—å—à–µ (Local_Less)",
        "–ë–æ–ª—å—à–µ (Local_More)",
        "–†–µ—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥ –∑–∞–ª–æ–≥ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ (Local_Secured_Refinancing)",
        "–î–µ–π—Å—Ç–≤—É—é—â–∏–π –∑–∞–π–º (Local_Current_MFO_2)",
        "General –ú–æ–∏ –∫—Ä–µ–¥–∏—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (General_My_loan_offers)",
        "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å/–ò–∑–º–µ–Ω–∏—Ç—å/–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å (Local_Setup_Secret_Code)",
        "–ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–º (Local_Trusted_Device)",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (Local_About_Trusted_Device)",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ —Å–µ–∫—Ä–µ—Ç–Ω—ã–π –∫–æ–¥ (Local_About_Secret_Code)",
        "–∑–∞–π–º—ã –±–æ–ª–µ–µ 100 —Ç—ã—Å (Local_MoreNumbers)",
        "–∑–∞–π–º—ã –º–µ–Ω—å—à–µ 100 —Ç—ã—Å (Local_LessNumbers)",
        "–ù–æ–≤–∞—è –∫–∞—Ä—Ç–∞ (NewCard)",
        "–ü—Ä–æ–±–ª–µ–º–∞ —Å –Ω–∞—á–∏—Å–ª–µ–Ω–∏–µ–º –∫—ç—à–±—ç–∫–∞ (Local_Problem_CashBack)"
    ]
    for topic in unused_topics:
        st.markdown(f"- {topic}")

# ============= TAB 3: –î–ê/–ù–ï–¢ =============
def render_phrases_grid(phrases, cols=3, color="#e0f7fa"):
    rows = [phrases[i:i+cols] for i in range(0, len(phrases), cols)]
    for row in rows:
        cols_streamlit = st.columns(cols)
        for col, phrase in zip(cols_streamlit, row):
            col.markdown(
                f"""<div style="background-color:{color};
                                padding:6px 10px;
                                border-radius:12px;
                                display:inline-block;
                                margin:4px;
                                font-size:14px;">{phrase}</div>""",
                unsafe_allow_html=True
            )

with tab3:
    st.markdown("### ‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ '–î–ê'")
    yes_phrases = [
        "–ü–æ–¥—Å–∫–∞–∑–∞—Ç—å", "–ü–æ–º–Ω—é", "–•–æ—Ä–æ—à–æ", "–î–∞", "–ê–≥–∞", "–£–≥—É",
        "–î–∞ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É", "–û—Å—Ç–∞–ª–∏—Å—å", "–ú–æ–∂–Ω–æ", "–ñ–≥–∏", "–í–∞–ª—è–π", "–ì–æ—Ç–æ–≤",
        "–ù—É-–Ω—É", "–ë—ã—Å—Ç—Ä–µ–µ", "–ü—Ä–æ–≤–µ—Ä—å", "–ü—Ä–æ–≤–µ—Ä—è–π", "–í—Å–µ —Ä–∞–≤–Ω–æ —Ö–æ—á—É",
        "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ", "–†–∞—Å—Å–∫–∞–∂–∏", "–°–∫–∞–∂–∏", "–ü—Ä–æ–≤–µ—Ä–∏–ª", "–î–∞–≤–∞–ª",
        "–Ø –º–æ–≥—É", "–£ –º–µ–Ω—è –≤–æ–ø—Ä–æ—Å –µ—Å—Ç—å", "–°–∫–∞–∑–∞–ª", "–ü—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π—Ç–µ", "–ü—Ä–æ–±–æ–≤–∞–ª–∞ –≤–Ω–æ—Å–∏—Ç–µ –≤ –≤–∞—à—É –±–∞–∑—É"
    ]
    render_phrases_grid(yes_phrases, cols=3, color="#d1f5d3")

    st.markdown("---")

    st.markdown("### ‚ùå –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ '–ù–ï–¢'")
    no_phrases = [
        "–ù–µ –Ω–∞–¥–æ", "–ù–µ —Ö–æ—á—É", "–ù–µ –≥–æ—Ç–æ–≤", "–ù–µ –ø–æ–º–Ω—é", "–ù–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞", "–ù–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ"
    ]
    render_phrases_grid(no_phrases, cols=3, color="#f9d6d5")
